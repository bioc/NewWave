sum(getEpsilon_gamma_pi(m)*(gamma_pi)^2)/2 +
sum(getEpsilon_W(m)*t(W)^2)/2 +
getEpsilon_zeta(m)*var(zeta)/2
message("After orthogonalization = ",
zinb.loglik(Y, itermu, exp(zeta), iterlP) - pen)
}
# 4. Optimize left factors
if (optimleft) {
ptm <- proc.time()
estimate <- matrix(unlist(
bplapply(seq(n), function(i) {
optimleft_fun(gamma_mu[,i], gamma_pi[,i], W[i,], Y[i,], V_mu, alpha_mu,
X_mu[i,], beta_mu, O_mu[i,], V_pi, alpha_pi, X_pi[i,],
beta_pi, O_pi[i,], zeta, epsilonleft)
})), nrow=sum(nleft))
if (verbose) {print(proc.time()-ptm)}
ind <- 1
if (nleft[1]>0) {
gamma_mu <- estimate[ind:(ind+nleft[1]-1),,drop=FALSE]
ind <- ind+nleft[1]
}
if (nleft[2]>0) {
gamma_pi <- estimate[ind:(ind+nleft[2]-1),,drop=FALSE]
ind <- ind+nleft[2]
}
if (nleft[3]>0) {
W <- t(estimate[ind:(ind+nleft[3]-1),,drop=FALSE])
ind <- ind+nleft[3]
}
}
# Evaluate total penalized likelihood
if (verbose) {
itermu <- exp(X_mu %*% beta_mu + t(V_mu %*% gamma_mu) +
W %*% alpha_mu + O_mu)
iterlP <- X_pi %*% beta_pi + t(V_pi %*% gamma_pi) +
W %*% alpha_pi + O_pi
pen <- sum(getEpsilon_alpha(m) * (alpha_mu)^2)/2 +
sum(getEpsilon_alpha(m) * (alpha_pi)^2)/2 +
sum(getEpsilon_beta_mu(m) * (beta_mu)^2)/2 +
sum(getEpsilon_beta_pi(m) * (beta_pi)^2)/2 +
sum(getEpsilon_gamma_mu(m)*(gamma_mu)^2)/2 +
sum(getEpsilon_gamma_pi(m)*(gamma_pi)^2)/2 +
sum(getEpsilon_W(m)*t(W)^2)/2 +
getEpsilon_zeta(m)*var(zeta)/2
message("After left optimization = ",
zinb.loglik(Y, itermu, exp(zeta), iterlP) - pen)
}
# 5. Orthogonalize
if (orthog) {
o <- orthogonalizeTraceNorm(W, cbind(alpha_mu,
alpha_pi),
m@epsilon_W, m@epsilon_alpha)
W <- o$U
alpha_mu <- o$V[,1:J,drop=FALSE]
alpha_pi <- o$V[,(J+1):(2*J),drop=FALSE]
}
# Evaluate total penalized likelihood
if (verbose) {
itermu <- exp(X_mu %*% beta_mu + t(V_mu %*% gamma_mu) +
W %*% alpha_mu + O_mu)
iterlP <- X_pi %*% beta_pi + t(V_pi %*% gamma_pi) +
W %*% alpha_pi + O_pi
pen <- sum(getEpsilon_alpha(m) * (alpha_mu)^2)/2 +
sum(getEpsilon_alpha(m) * (alpha_pi)^2)/2 +
sum(getEpsilon_beta_mu(m) * (beta_mu)^2)/2 +
sum(getEpsilon_beta_pi(m) * (beta_pi)^2)/2 +
sum(getEpsilon_gamma_mu(m)*(gamma_mu)^2)/2 +
sum(getEpsilon_gamma_pi(m)*(gamma_pi)^2)/2 +
sum(getEpsilon_W(m)*t(W)^2)/2 +
getEpsilon_zeta(m)*var(zeta)/2
message("After orthogonalization = ",
zinb.loglik(Y, itermu, exp(zeta), iterlP) - pen)
}
W_optim <- append(W_optim, list(W))
}
}
system.time(my_zinb_bp(Y,X))
my_zinb_bp <- function(Y,X){
BPPARAM = MulticoreParam(workers = 8)
Y = Y
X = X
m <- zinbwave::zinbModel(n=NROW(Y), J=NCOL(Y), K=2, X=X)
nb.repeat <- 2
it.max <- 100
verbose <- F
n <- NROW(Y)
J <- NCOL(Y)
if(n != nSamples(m)) {
stop("Y needs to have ", nSamples(m), " rows (genes)")
}
if(J != nFeatures(m)) {
stop("Y needs to have ", nFeatures(m), " columns (samples)")
}
## 1. Define P
P <- Y > 0
if(any(rowSums(P) == 0)) {
stop("Sample ", which(rowSums(P) == 0)[1], " has only 0 counts!")
}
if(any(colSums(P) == 0)) {
stop("Gene ", which(colSums(P) == 0)[1], " has only 0 counts!")
}
## 2. Define L
L <- matrix(NA, nrow=n, ncol=J)
L[P] <- log(Y[P]) - m@O_mu[P]
## 3. Define Z
Z <- 1 - P
## 4. Estimate gamma_mu and beta_mu
iter <- 0
beta_mu <- getBeta_mu(m)
gamma_mu <- getGamma_mu(m)
while (iter < nb.repeat) {
# Optimize gamma_mu (in parallel for each sample)
if (NCOL(getV_mu(m)) == 0) {
iter <- nb.repeat # no need to estimate gamma_mu nor to iterate
} else {
Xbeta_mu <- getX_mu(m) %*% beta_mu
gamma_mu <- matrix(unlist(bplapply(seq(n), function(i) {
solveRidgeRegression(x=getV_mu(m)[P[i,], , drop=FALSE],
y=L[i,P[i,]] - Xbeta_mu[i, P[i,]],
epsilon = getEpsilon_gamma_mu(m),
family="gaussian")
}
)), nrow=NCOL(getV_mu(m)))
}
# Optimize beta_mu (in parallel for each gene)
if (NCOL(getX_mu(m)) == 0) {
iter <- nb.repeat # no need to estimate gamma_mu nor to iterate
} else {
tVgamma_mu <- t(getV_mu(m) %*% gamma_mu)
beta_mu <- matrix(unlist(bplapply(seq(J), function(j) {
solveRidgeRegression(x=getX_mu(m)[P[,j], , drop=FALSE],
y=L[P[,j],j] - tVgamma_mu[P[,j], j],
epsilon = getEpsilon_beta_mu(m),
family="gaussian")
}
)), nrow=NCOL(getX_mu(m)))
}
iter <- iter+1
}
## 5. Estimate W and alpha (only if K>0)
if(nFactors(m) > 0) {
# Compute the residual D (with missing values at the 0 count)
D <- L - getX_mu(m) %*% beta_mu - t(getV_mu(m) %*% gamma_mu)
# Find a low-rank approximation with trace-norm regularization
lambda <- sqrt(getEpsilon_W(m) * getEpsilon_alpha(m))[1]
R <- softImpute::softImpute(D,
lambda=lambda,
rank.max=nFactors(m), maxit=it.max)
while(length(R$d) < nFactors(m)) {
lambda <- lambda/2
R <- softImpute::softImpute(D,
lambda=lambda,
rank.max=nFactors(m), maxit=it.max)
}
# Orthogonalize to get W and alpha
W <- (getEpsilon_alpha(m) / getEpsilon_W(m))[1]^(1/4) *
R$u %*% diag(sqrt(R$d), nrow = length(R$d))
alpha_mu <- (getEpsilon_W(m)/getEpsilon_alpha(m))[1]^(1/4) *
diag(sqrt(R$d), nrow = length(R$d)) %*% t(R$v)
} else {
W <- getW(m)
alpha_mu <- getAlpha_mu(m)
}
## 6. Estimate beta_pi, gamma_pi, and alpha_pi
iter <- 0
beta_pi <- getBeta_pi(m)
gamma_pi <- getGamma_pi(m)
alpha_pi <- getAlpha_pi(m)
while (iter < nb.repeat) {
# Optimize gamma_pi (in parallel for each sample)
if (NCOL(getV_pi(m)) == 0) {
iter <- nb.repeat # no need to estimate gamma_pi nor to iterate
} else {
off <- getX_pi(m) %*% beta_pi + W %*% alpha_pi
gamma_pi <- matrix(unlist(bplapply(seq(n), function(i) {
solveRidgeRegression(x=getV_pi(m),
y=Z[i,],
offset=off[i,],
epsilon = getEpsilon_gamma_pi(m),
family="binomial")
}, BPPARAM=BPPARAM
)), nrow=NCOL(getV_pi(m)))
}
# Optimize beta_pi and alpha_pi (in parallel for each gene)
if (NCOL(getX_pi(m)) + nFactors(m) == 0) {
iter <- nb.repeat # no need to estimate nor to iterate
} else {
tVgamma_pi <- t(getV_pi(m) %*% gamma_pi)
XW <- cbind(getX_pi(m),W)
s <- matrix(unlist(bplapply(seq(J), function(j) {
solveRidgeRegression(x=XW,
y=Z[,j],
offset = tVgamma_pi[,j],
epsilon = c(getEpsilon_beta_pi(m),
getEpsilon_alpha(m)),
family="binomial")
}, BPPARAM=BPPARAM
)), nrow=NCOL(getX_pi(m)) + nFactors(m))
if (NCOL(getX_pi(m))>0) {
beta_pi <- s[1:NCOL(getX_pi(m)),,drop=FALSE]
}
if (nFactors(m)>0) {
alpha_pi <-
s[(NCOL(getX_pi(m)) + 1):(NCOL(getX_pi(m)) + nFactors(m)),,
drop=FALSE]
}
}
iter <- iter+1
}
## 7. Initialize dispersion to 1
zeta <- rep(0, J)
W_iniz <- W
m <- zinbModel(X = m@X, V = m@V, O_mu = m@O_mu, O_pi = m@O_pi,
which_X_mu = m@which_X_mu, which_X_pi = m@which_X_pi,
which_V_mu = m@which_V_mu, which_V_pi = m@which_V_pi,
W = W, beta_mu = beta_mu, beta_pi = beta_pi,
gamma_mu = gamma_mu, gamma_pi = gamma_pi,
alpha_mu = alpha_mu, alpha_pi = alpha_pi, zeta = zeta,
epsilon_beta_mu = m@epsilon_beta_mu,
epsilon_gamma_mu = m@epsilon_gamma_mu,
epsilon_beta_pi = m@epsilon_beta_pi,
epsilon_gamma_pi = m@epsilon_gamma_pi,
epsilon_W = m@epsilon_W, epsilon_alpha = m@epsilon_alpha,
epsilon_zeta = m@epsilon_zeta,
epsilon_min_logit = m@epsilon_min_logit)
maxiter = 25
W_optim <- list()
total.lik=rep(NA,maxiter)
n <- nSamples(m)
J <- nFeatures(m)
epsilonright <- c(getEpsilon_beta_mu(m), getEpsilon_alpha(m),
getEpsilon_beta_pi(m), getEpsilon_alpha(m))
nright <- c(length(getEpsilon_beta_mu(m)), length(getEpsilon_alpha(m)),
length(getEpsilon_beta_pi(m)), length(getEpsilon_alpha(m)))
optimright = (sum(nright)>0)
epsilonleft <- c(getEpsilon_gamma_mu(m),
getEpsilon_gamma_pi(m), getEpsilon_W(m))
nleft <- c(length(getEpsilon_gamma_mu(m)),
length(getEpsilon_gamma_pi(m)), length(getEpsilon_W(m)))
optimleft = (sum(nleft)>0)
orthog <- (nFactors(m)>0)
# extract fixed quantities from m
X_mu <- getX_mu(m)
V_mu <- getV_mu(m)
X_pi <- getX_pi(m)
V_pi <- getV_pi(m)
O_mu <- m@O_mu
O_pi <- m@O_pi
# exctract paramters from m (remember to update!)
beta_mu <- getBeta_mu(m)
alpha_mu <- getAlpha_mu(m)
gamma_mu <- getGamma_mu(m)
beta_pi <- getBeta_pi(m)
alpha_pi <- getAlpha_pi(m)
gamma_pi <- getGamma_pi(m)
W <- getW(m)
zeta <- getZeta(m)
for (iter in seq_len(maxiter)){
if (verbose) {message("Iteration ",iter)}
# Evaluate total penalized likelihood
mu <- exp(X_mu %*% beta_mu + t(V_mu %*% gamma_mu) +
W %*% alpha_mu + O_mu)
logitPi <- X_pi %*% beta_pi + t(V_pi %*% gamma_pi) +
W %*% alpha_pi + O_pi
theta <- exp(zeta)
loglik <- zinb.loglik(Y, mu, rep(theta, rep(n, J)), logitPi)
penalty <- sum(getEpsilon_alpha(m) * (alpha_mu)^2)/2 +
sum(getEpsilon_alpha(m) * (alpha_pi)^2)/2 +
sum(getEpsilon_beta_mu(m) * (beta_mu)^2)/2 +
sum(getEpsilon_beta_pi(m) * (beta_pi)^2)/2 +
sum(getEpsilon_gamma_mu(m)*(gamma_mu)^2)/2 +
sum(getEpsilon_gamma_pi(m)*(gamma_pi)^2)/2 +
sum(getEpsilon_W(m)*t(W)^2)/2 +
getEpsilon_zeta(m)*var(zeta)/2
total.lik[iter] <- loglik - penalty
if (verbose) {message("penalized log-likelihood = ",
total.lik[iter])}
# If the increase in likelihood is smaller than 0.5%, stop maximization
if(iter > 1){
if(abs((total.lik[iter]-total.lik[iter-1]) /
total.lik[iter-1])<0.0001)
break
}
# 1. Optimize dispersion
zeta <- zinbOptimizeDispersion(J, mu, logitPi, getEpsilon_zeta(m), Y,
commondispersion=TRUE,
BPPARAM=BPPARAM)
# Evaluate total penalized likelihood
if (verbose) {
pen <- sum(getEpsilon_alpha(m) * (alpha_mu)^2)/2 +
sum(getEpsilon_alpha(m) * (alpha_pi)^2)/2 +
sum(getEpsilon_beta_mu(m) * (beta_mu)^2)/2 +
sum(getEpsilon_beta_pi(m) * (beta_pi)^2)/2 +
sum(getEpsilon_gamma_mu(m)*(gamma_mu)^2)/2 +
sum(getEpsilon_gamma_pi(m)*(gamma_pi)^2)/2 +
sum(getEpsilon_W(m)*t(W)^2)/2 +
getEpsilon_zeta(m)*var(zeta)/2
message("After dispersion optimization = ",
zinb.loglik(Y, mu, exp(zeta), logitPi) - pen)
}
# 2. Optimize right factors
if (optimright) {
ptm <- proc.time()
estimate <- matrix(unlist(
bplapply(seq(J), function(j) {
optimright_fun(beta_mu[,j], alpha_mu[,j], beta_pi[,j], alpha_pi[,j],
Y[,j], X_mu, W, V_mu[j,], gamma_mu, O_mu[,j], X_pi,
V_pi[j,], gamma_pi, O_pi[,j], zeta[j], n, epsilonright)
})), nrow=sum(nright))
if (verbose) {print(proc.time()-ptm)}
ind <- 1
if (nright[1]>0) {
beta_mu <- estimate[ind:(ind+nright[1]-1),,drop=FALSE]
ind <- ind+nright[1]
}
if (nright[2]>0) {
alpha_mu <- estimate[ind:(ind+nright[2]-1),,drop=FALSE]
ind <- ind+nright[2]
}
if (nright[3]>0) {
beta_pi <- estimate[ind:(ind+nright[3]-1),,drop=FALSE]
ind <- ind+nright[3]
}
if (nright[4]>0) {
alpha_pi <- estimate[ind:(ind+nright[4]-1),,drop=FALSE]
}
}
# Evaluate total penalized likelihood
if (verbose) {
itermu <- exp(X_mu %*% beta_mu + t(V_mu %*% gamma_mu) +
W %*% alpha_mu + O_mu)
iterlP <- X_pi %*% beta_pi + t(V_pi %*% gamma_pi) +
W %*% alpha_pi + O_pi
pen <- sum(getEpsilon_alpha(m) * (alpha_mu)^2)/2 +
sum(getEpsilon_alpha(m) * (alpha_pi)^2)/2 +
sum(getEpsilon_beta_mu(m) * (beta_mu)^2)/2 +
sum(getEpsilon_beta_pi(m) * (beta_pi)^2)/2 +
sum(getEpsilon_gamma_mu(m)*(gamma_mu)^2)/2 +
sum(getEpsilon_gamma_pi(m)*(gamma_pi)^2)/2 +
sum(getEpsilon_W(m)*t(W)^2)/2 +
getEpsilon_zeta(m)*var(zeta)/2
message("After right optimization = ",
zinb.loglik(Y, itermu, exp(zeta), iterlP) - pen)
}
# 3. Orthogonalize
if (orthog) {
o <- orthogonalizeTraceNorm(W, cbind(alpha_mu,
alpha_pi),
m@epsilon_W, m@epsilon_alpha)
W <- o$U
alpha_mu <- o$V[,1:J,drop=FALSE]
alpha_pi <- o$V[,(J+1):(2*J),drop=FALSE]
}
# Evaluate total penalized likelihood
if (verbose) {
itermu <- exp(X_mu %*% beta_mu + t(V_mu %*% gamma_mu) +
W %*% alpha_mu + O_mu)
iterlP <- X_pi %*% beta_pi + t(V_pi %*% gamma_pi) +
W %*% alpha_pi + O_pi
pen <- sum(getEpsilon_alpha(m) * (alpha_mu)^2)/2 +
sum(getEpsilon_alpha(m) * (alpha_pi)^2)/2 +
sum(getEpsilon_beta_mu(m) * (beta_mu)^2)/2 +
sum(getEpsilon_beta_pi(m) * (beta_pi)^2)/2 +
sum(getEpsilon_gamma_mu(m)*(gamma_mu)^2)/2 +
sum(getEpsilon_gamma_pi(m)*(gamma_pi)^2)/2 +
sum(getEpsilon_W(m)*t(W)^2)/2 +
getEpsilon_zeta(m)*var(zeta)/2
message("After orthogonalization = ",
zinb.loglik(Y, itermu, exp(zeta), iterlP) - pen)
}
# 4. Optimize left factors
if (optimleft) {
ptm <- proc.time()
estimate <- matrix(unlist(
bplapply(seq(n), function(i) {
optimleft_fun(gamma_mu[,i], gamma_pi[,i], W[i,], Y[i,], V_mu, alpha_mu,
X_mu[i,], beta_mu, O_mu[i,], V_pi, alpha_pi, X_pi[i,],
beta_pi, O_pi[i,], zeta, epsilonleft)
})), nrow=sum(nleft))
if (verbose) {print(proc.time()-ptm)}
ind <- 1
if (nleft[1]>0) {
gamma_mu <- estimate[ind:(ind+nleft[1]-1),,drop=FALSE]
ind <- ind+nleft[1]
}
if (nleft[2]>0) {
gamma_pi <- estimate[ind:(ind+nleft[2]-1),,drop=FALSE]
ind <- ind+nleft[2]
}
if (nleft[3]>0) {
W <- t(estimate[ind:(ind+nleft[3]-1),,drop=FALSE])
ind <- ind+nleft[3]
}
}
# Evaluate total penalized likelihood
if (verbose) {
itermu <- exp(X_mu %*% beta_mu + t(V_mu %*% gamma_mu) +
W %*% alpha_mu + O_mu)
iterlP <- X_pi %*% beta_pi + t(V_pi %*% gamma_pi) +
W %*% alpha_pi + O_pi
pen <- sum(getEpsilon_alpha(m) * (alpha_mu)^2)/2 +
sum(getEpsilon_alpha(m) * (alpha_pi)^2)/2 +
sum(getEpsilon_beta_mu(m) * (beta_mu)^2)/2 +
sum(getEpsilon_beta_pi(m) * (beta_pi)^2)/2 +
sum(getEpsilon_gamma_mu(m)*(gamma_mu)^2)/2 +
sum(getEpsilon_gamma_pi(m)*(gamma_pi)^2)/2 +
sum(getEpsilon_W(m)*t(W)^2)/2 +
getEpsilon_zeta(m)*var(zeta)/2
message("After left optimization = ",
zinb.loglik(Y, itermu, exp(zeta), iterlP) - pen)
}
# 5. Orthogonalize
if (orthog) {
o <- orthogonalizeTraceNorm(W, cbind(alpha_mu,
alpha_pi),
m@epsilon_W, m@epsilon_alpha)
W <- o$U
alpha_mu <- o$V[,1:J,drop=FALSE]
alpha_pi <- o$V[,(J+1):(2*J),drop=FALSE]
}
# Evaluate total penalized likelihood
if (verbose) {
itermu <- exp(X_mu %*% beta_mu + t(V_mu %*% gamma_mu) +
W %*% alpha_mu + O_mu)
iterlP <- X_pi %*% beta_pi + t(V_pi %*% gamma_pi) +
W %*% alpha_pi + O_pi
pen <- sum(getEpsilon_alpha(m) * (alpha_mu)^2)/2 +
sum(getEpsilon_alpha(m) * (alpha_pi)^2)/2 +
sum(getEpsilon_beta_mu(m) * (beta_mu)^2)/2 +
sum(getEpsilon_beta_pi(m) * (beta_pi)^2)/2 +
sum(getEpsilon_gamma_mu(m)*(gamma_mu)^2)/2 +
sum(getEpsilon_gamma_pi(m)*(gamma_pi)^2)/2 +
sum(getEpsilon_W(m)*t(W)^2)/2 +
getEpsilon_zeta(m)*var(zeta)/2
message("After orthogonalization = ",
zinb.loglik(Y, itermu, exp(zeta), iterlP) - pen)
}
W_optim <- append(W_optim, list(W))
}
}
system.time(my_zinb_bp(Y,X))
library(gdata)
library(ggplot2)
library(lsmeans)
library(limma)
library(nnet)
load("~/Scrivania/tesi-angelo/cnv_mir.RData")
load("~/Scrivania/tesi-angelo/miRNA_cnv.RData")
annotation <- read.csv("~/Scrivania/tesi-angelo/dati-fin/annotation.csv", row.names="X")
boxplot(miRNA_cnv)
load("~/Scrivania/tesi-angelo/cnv_mir.RData")
load("~/Scrivania/tesi-angelo/miRNA_cnv.RData")
annotation <- read.csv("~/Scrivania/tesi-angelo/dati-fin/annotation.csv", row.names="X")
boxplot(miRNA_cnv)
miRNA_cnv <- normalizeQuantiles(miRNA_cnv)
boxplot(miRNA_cnv)
cnv_model <- as.data.frame(t(cnv_mirbase))
cnv_model <- as.data.frame(t(cnv))
miRNA_model <- as.data.frame(t(miRNA_cnv))
sum(is.na(miRNA_model))
View(cnv_model)
View(miRNA_model)
cnv_model <- cnv_model[which(rownames(cnv_model) %in% rownames(miRNA_model)),]
miRNA_model <- miRNA_model[which(rownames(miRNA_model) %in% rownames(cnv_model)),]
sum(is.na(miRNA_model))
cnv_model[sapply(cnv_model, is.integer)] <- lapply(cnv_model[sapply(cnv_model,is.integer)],
as.factor)
cnv_model[sapply(cnv_model, is.factor)] <- lapply(cnv_model[sapply(cnv_model,is.factor)],
relevel, ref = "0")
risultati <- list()
for (i in 1:82){
results <- list(summary(lm(miRNA_model[,i]~cnv_model[,i]))$coefficients[,c(1,4)])
risultati<-append(risultati,results)
}
names(risultati) <- colnames(cnv_model)
risultati <- list()
for (i in 1:127){
results <- list(summary(lm(miRNA_model[,i]~cnv_model[,i]))$coefficients[,c(1,4)])
risultati<-append(risultati,results)
}
names(risultati) <- colnames(cnv_model)
selector <- function(x , argument){
if( argument %in% rownames(x) ){
x[ which(rownames(x) == argument),]
} else { matrix(0,2,1)}
}
intercept <- t(sapply(risultati, selector, argument="(Intercept)"))
beta_two_deletion <- t(sapply(risultati, selector, argument="cnv_model[, i]-2"))
beta_one_deletion <- t(sapply(risultati, selector, argument="cnv_model[, i]-1"))
beta_one_gain <- t(sapply(risultati, selector, argument="cnv_model[, i]1"))
beta_two_gain <- t(sapply(risultati, selector, argument="cnv_model[, i]2"))
beta_two_deletion[which(beta_two_deletion[,1]==0),] <- NA
beta_one_deletion[which(beta_one_deletion[,1]==0),] <- NA
beta_one_gain[which(beta_one_gain[,1]==0),] <- NA
beta_two_gain[which(beta_two_gain[,1]==0),] <- NA
par(mfrow = c(1,2))
hist(beta_two_deletion[,1], main = "Valore dei beta",breaks=20)
hist(beta_two_deletion[,2], main = "Valore dei p-value",breaks=20)
hist(beta_one_deletion[,1], main = "Valore dei beta", breaks = 20)
hist(beta_one_deletion[,2], main = "Valore dei p-value", breaks = 20)
hist(beta_one_gain[,1], main = "Valore dei beta", breaks = 20)
hist(beta_one_gain[,2], main = "Valore dei p-value", breaks = 20)
hist(beta_two_gain[,1], main = "Valore dei beta", breaks = 20)
hist(beta_two_gain[,2], main = "Valore dei p-value", breaks = 20)
par(mfrow = c(2,2))
hist(beta_two_deletion[which(beta_two_deletion[,2] < 0.05),1], main = "Parametri due delezioni")
par(mfrow = c(2,2))
hist(beta_two_deletion[which(beta_two_deletion[,2] < 0.05),1], main = "Parametri due delezioni")
par(mfrow = c(2,2))
hist(beta_two_deletion[which(beta_two_deletion[,2] < 0.05),1], main = "Parametri due delezioni")
install.packages("Matrix")
source('~/Scrivania/prove_zinb_par/Test_pacchetto.R')
